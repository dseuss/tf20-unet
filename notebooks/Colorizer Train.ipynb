{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Colorizer","version":"0.3.2","provenance":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"ThHNR11Y8yNB","colab_type":"code","colab":{}},"source":["!pip install tensorflow==2.0.0beta1 tensorflow-datasets pillow"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jbsWMA55cKr_","colab_type":"code","colab":{}},"source":["%load_ext autoreload\n","%autoreload 2\n","%load_ext tensorboard"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ohXhT4FMby7m","colab_type":"code","colab":{}},"source":["# Run this cell to mount your Google Drive. Alternatively, clone the git repo\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.append('/content/drive/My Drive/Code/colab_workflow')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ea-8nejVS-Np","colab_type":"code","colab":{}},"source":["import os\n","import tensorflow as tf\n","TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","tf.config.experimental_connect_to_host(TPU_WORKER, 'tpu_worker')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCHQ15adcVCh","colab_type":"code","colab":{}},"source":["import functools as ft\n","import tensorflow as tf\n","import tensorflow.keras as k\n","import tensorflow_datasets as tfds\n","import numpy as np\n","from PIL import Image\n","from IPython.display import display\n","from tqdm import tqdm_notebook as tqdm\n","\n","from models import Unet"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vJcaYXgF98dT","colab_type":"code","colab":{}},"source":["def to_grayscale(image):\n","    x = tf.image.rgb_to_grayscale(image)\n","    return {'x': x, 'y': image}\n","\n","def show_img(tensor):\n","    img = tensor.numpy().astype(np.uint8).squeeze()\n","    display(Image.fromarray(img))\n","\n","def build_dataset(split):\n","    data = tfds.load('voc2007', split=split)\n","    data = data.map(lambda s: s['image'])\n","    data = data.map(ft.partial(tf.image.resize_with_pad, target_height=320, target_width=320))\n","    data = data.map(to_grayscale)\n","    return data\n","\n","ds_test = build_dataset(tfds.Split.TEST)\n","for features in ds_test.take(1):\n","    pass\n","show_img(features['x'])\n","show_img(features['y'])\n","ds_test = ds_test.batch(8).prefetch(10)\n","\n","ds_train = build_dataset(tfds.Split.TRAIN)\n","ds_train = ds_train.shuffle(128).batch(8).prefetch(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGR4W9MWD4ln","colab_type":"code","colab":{}},"source":["loss_fn = k.losses.MeanSquaredError()\n","optimizer = k.optimizers.Adam()\n","\n","model = Unet(output_channels=3, num_filters=[64, 128, 256])\n","metrics = {\n","    'train_loss': k.metrics.Mean(name='train_loss'),\n","    'test_loss': k.metrics.Mean(name='train_loss'),\n","}\n","\n","@tf.function\n","def train_step(x, y):\n","    with tf.GradientTape() as tape:\n","        y_pred = model(x)\n","        loss = loss_fn(y, y_pred)\n","        grad = tape.gradient(loss, model.trainable_variables)\n","        optimizer.apply_gradients(zip(grad, model.trainable_variables))\n","    \n","    metrics['train_loss'](loss)\n","    \n","@tf.function\n","def test_step(x, y):\n","    y_pred = model(x)\n","    loss = loss_fn(y, y_pred)\n","    metrics['test_loss'](loss)\n","    \n","    \n","for epoch in range(1):\n","    for data in tqdm(ds_train):\n","        train_step(**data)\n","        \n","    for data in tqdm(ds_test):\n","        test_step(**data)\n","    \n","    metric_strs = (f'{name}={value.result():.04f}' for name, value in metrics.items())\n","    print(f'[{epoch}] ' + ' '.join(metric_strs))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMYnm4FUMLT9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}